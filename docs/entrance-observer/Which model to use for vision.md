- YoloV5 ‚Üê current
- YoloV8
    - [https://docs.ultralytics.com/guides/object-counting/#what-is-object-counting](https://docs.ultralytics.com/guides/object-counting/#what-is-object-counting)
    - [https://docs.ultralytics.com/guides/nvidia-jetson/#nvidia-jetson-orin-yolov8-benchmarks](https://docs.ultralytics.com/guides/nvidia-jetson/#nvidia-jetson-orin-yolov8-benchmarks)
- YoloV6-v3 at 1280px, GPL-3.0, from source code
- [https://github.com/lyuwenyu/RT-DETR](https://github.com/lyuwenyu/RT-DETR) with 54.8 mAP
- [https://github.com/jozhang97/DETA](https://github.com/jozhang97/DETA) 63.5 mAP
- MCUNet ? [https://github.com/mit-han-lab/mcunet](https://github.com/mit-han-lab/mcunet)

Zero-shot models seem pretty bad:

- YoloWorld
- OWL + CLIP
- OWL + ViT
- LLaVA 1.5 = detect everything
- NanoOWL [github.com/NVIDIA-AI-IOT/nanoowl](http://github.com/NVIDIA-AI-IOT/nanoowl)

Hardware

- RTX
- A100

Runtimes

- Pytorch
- TensorRT
- ONNX

![](../img/Screenshot%202023-11-07%20at%2020.25.33.png)

<iframe width="100%" height="400" src="https://www.youtube.com/embed/dL9B9VUHkgQ" title="Top Object Detection Models in 2023 | Model Selection Guide sponsored by Intel" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>